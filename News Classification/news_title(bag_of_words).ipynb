{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json('/home/leviathan/Downloads/News_Category_Dataset.json',lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['authors','date','link'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['category', 'headline', 'short_description'], dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downsampling Polytics and Entertainment category #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_down = df[df.category=='POLITICS']\n",
    "df_down = df_down[:3500]\n",
    "df  = df[df.category != 'POLITICS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df,df_down])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_down = df[df.category=='ENTERTAINMENT']\n",
    "df_down = df_down[:3500]\n",
    "df  = df[df.category != 'ENTERTAINMENT']\n",
    "df = pd.concat([df,df_down])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(84993, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('category',axis=1)\n",
    "Y = df.category\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(84993, 2) (84993,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape,Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['data'] = X.headline +\" \"+ X.short_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "Y = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(63744,) (21249,)\n"
     ]
    }
   ],
   "source": [
    "xtrain,xtest,ytrain,ytest = train_test_split(X,Y,random_state=0)\n",
    "print(xtrain.shape, xtest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(63744, 59258) (21249, 59258)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vect = CountVectorizer(analyzer='word',stop_words='english', token_pattern=r'\\w{1,}')\n",
    "training_data = count_vect.fit_transform(xtrain)\n",
    "testing_data = count_vect.transform(xtest)\n",
    "print(training_data.shape, testing_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(63744, 19287) (21249, 19287)\n"
     ]
    }
   ],
   "source": [
    "tfidf_vector = TfidfVectorizer(analyzer='char', token_pattern=r'\\w{1,}', ngram_range=(2,3), max_features=50000)\n",
    "X_train = tfidf_vector.fit_transform(xtrain) # training data\n",
    "X_test = tfidf_vector.transform(xtest) #test data\n",
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "naive_bayes = MultinomialNB()\n",
    "naive_bayes.fit(training_data, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.516683138030025"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naive_bayes.score(testing_data,ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = naive_bayes.predict(testing_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score:  0.516683138030025\n",
      "Recall score:  0.516683138030025\n",
      "Precision score:  0.5686545803063483\n",
      "F1 score:  0.49119880901835455\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "\n",
    "print(\"Accuracy score: \", accuracy_score(ytest, predictions))\n",
    "print(\"Recall score: \", recall_score(ytest, predictions, average = 'weighted'))\n",
    "print(\"Precision score: \", precision_score(ytest, predictions, average = 'weighted'))\n",
    "print(\"F1 score: \", f1_score(ytest, predictions, average = 'weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "arr=confusion_matrix(ytest,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[494   4   1   1  13  18  47   7   1  17  10   9   0   2   0   0   0   0\n",
      "   0   0  11   0   0   7   2  20  28   1   1   0   0]\n",
      "[  9 514   1   3  20   6  60  24  71  64  22  10   6   9   0   1   0   0\n",
      "   0   0  28   3   6   4   4  28   0   0   1   0   1]\n",
      "[ 27   1  76  12  30   2   5   7   2  23   5  15   2   6   0  21   1   0\n",
      "   0   1   2   0   1  29   1   8 260   0  27   0   0]\n",
      "[  3   3   1 188   8   1  21  25   4  38   7  58   4   1   1   4   0   0\n",
      "   2   0  38   0   1  23   2 183  23   0  10   0   0]\n",
      "[ 10  10   4   2 595   0  16  23  36  19   8  29   0  18   0   3   1   0\n",
      "   3   1   4   0   1  15   0  36  27   0   1   0   0]\n",
      "[ 89  15   0   2  10 174   7  11  57  34  51  20  10   2   1   2   8   0\n",
      "   0   0  63   1   3  26  19  61  12   2   0   0   2]\n",
      "[ 69  52   0   9  31   1 538  17  15  58  34  13   1   5   0   7   0   0\n",
      "   2   3  29   0   3   0   1  52   6   0   2   0   4]\n",
      "[  6  25   0  15  30   2  15 318  12  57  16  35   0  18   0   2   0   1\n",
      "   0   2  57   0  11   1   2 184   9   0   0   1   0]\n",
      "[  1  72   1   4  46  13  21  27 483  27  28  21   3  18   2   6   1   1\n",
      "   0   0  54   0   4   6   9 105   3   1   3   0   1]\n",
      "[ 12  29   0   3  27   0  20  24  10 948  22   8   5   8   0   4   0   0\n",
      "   2   1  37   1   1   1   3  55   7   0   1   0   2]\n",
      "[ 17  19   1   4  13   6  24  10  22  21 786   7   6  11   0   2   0   0\n",
      "   0   0  12   0   2   0   2  38   9   0   7   0   0]\n",
      "[ 12   8   1   9  42   1  10  23  10  19  12 659   1  14   4   2   0   0\n",
      "   3   0  17   0   2  18  14 176   9   0   7   0   0]\n",
      "[  5   3   1   2   6   6   3   3   6  15   7  23 285   0   0   4   0   0\n",
      "   0   0  24   1   2  16  15 107  14   1   3   0   3]\n",
      "[  4  15   1   3  66   0  25  16  39  16   7  44   0 358   0   1   0   0\n",
      "   1   1   5   0   3   1   1  25  23   0   6   0   0]\n",
      "[ 9  8  0  1 18  6  8 11  8 10  5 98  1 10 40  2  0  0  0  0  8  0  0  0\n",
      "  2 50 11  0  0  0  2]\n",
      "[ 10   7   1  14  21   4  25  14   8  68   4  12   4   5   0 311   1   0\n",
      "   0   0  24   0   2   3   4  59  24   0  15   0   1]\n",
      "[  2   3   0   2   1  13   7   4   6  11   5  12   7   2   0   1  84   0\n",
      "   0   0  13   0   1  46   1 128   2   1   3   1   2]\n",
      "[ 5 26  1  7 42  3 27 11 14 29 11 11  0  9  0  1  0 33  0  0 20  0  3  1\n",
      "  3 19 10  0  6  1  1]\n",
      "[ 1  0  0 24 24  0 10  3  0  9  4 28  0  4  1  2  0  0 47  9 25  0  0  1\n",
      "  1 59  1  0  2  0  1]\n",
      "[12  0  0 10 16  2 23 18  1 19 11 36  0  6  1  2  0  0  5 57 11  0  0  4\n",
      "  1 60  1  0  2  0  0]\n",
      "[  4  12   0   5   2   6  15  12  10  29  15  15   1   4   0   0   0   0\n",
      "   2   1 692   1   2   3   2 177   1   1   0   0   0]\n",
      "[ 4 29  1  5  8  6 28 32 19 76  1 11  3  7  0  3  0  1  0  0 18 26  3  3\n",
      "  1 44  8  0  2  0 30]\n",
      "[  0  36   1   1   3   4  19  36  11  40  11  21   2   1   0   0   0   0\n",
      "   0   0  39   0 225   3   6  90   1   1   1   0   3]\n",
      "[ 24   1   1  19  31  18   5   3   7  12   8  43   9   6   0   0   2   0\n",
      "   0   0  28   0   0 348   2  79  19   1   3   0   1]\n",
      "[  0  11   0   5   8   2   5   2  11   6   2  12   6   2   0   1   1   0\n",
      "   0   0  24   0   2   2 292 105   1   0   1   0   2]\n",
      "[   8    6    0   16   16    4    8   16    8   25    9   46    8    2\n",
      "    0    4    1    0    0    0   58    0    3   12   19 1435   14    0\n",
      "    2    0    0]\n",
      "[ 21   3  22  15  40   2   6  14   5  23   9  19   6   9   1  10   1   0\n",
      "   0   0   6   1   0  20   0  18 604   0  54   0   1]\n",
      "[25 11  0 28  0 27  8  7  8 28  8 11  4  1  0  0  0  0  0  0 70  0  5 23\n",
      "  3 54  5 30  0  0  0]\n",
      "[ 10   2  12  29   8   1   2  10   4  14   9  31   4   9   0  10   0   0\n",
      "   1   0   6   1   0  15   0  36 214   1 217   0   2]\n",
      "[  1   4   0   5   1   2   2  17   1  14   5  28   4   2   0   1   1   0\n",
      "   0   0  63   1   6   1   7 185   1   0   1  24   0]\n",
      "[ 4 17  0  6  3  3 13  8  5 53  6 22 14  3  0  5  0  0  0  0 18  7  1  9\n",
      "  1 51  5  1  4  0 98]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=10)\n",
    "knn.fit(training_data, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
